{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfrVK4yDPb7-",
        "outputId": "88fed049-3c3b-4f20-f0b7-2dfc9fd77f51"
      },
      "outputs": [],
      "source": [
        "!pip install 'shimmy>=2.0'\n",
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCXU8qHbN4fP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "from stable_baselines3 import PPO\n",
        "from scipy.sparse import csr_matrix, issparse\n",
        "from scipy.sparse.linalg import eigsh\n",
        "from scipy.spatial.distance import cosine\n",
        "from stable_baselines3 import SAC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEEOXhXtN9Ez"
      },
      "outputs": [],
      "source": [
        "# Power method for warm-start initialization\n",
        "def power_method(A, num_iterations=10):\n",
        "    x = np.random.randn(A.shape[0])\n",
        "    x /= np.linalg.norm(x)\n",
        "    for _ in range(num_iterations):\n",
        "        x = A.dot(x) if issparse(A) else A @ x\n",
        "        x /= np.linalg.norm(x) + 1e-8\n",
        "    return x\n",
        "\n",
        "# Define RL Environment for Eigenvector Search\n",
        "class EigenvectorEnv(gym.Env):\n",
        "    def __init__(self, A, target_eigenvalue):\n",
        "        super(EigenvectorEnv, self).__init__()\n",
        "        self.A = A\n",
        "        self.target_eigenvalue = target_eigenvalue\n",
        "        self.dim = A.shape[0]\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.dim,), dtype=np.float32)\n",
        "        self.action_space = spaces.Box(low=-1, high=1, shape=(self.dim,), dtype=np.float32)\n",
        "        self.state = None\n",
        "        # Compute Frobenius norm for normalization\n",
        "        self.A_norm = np.sqrt(np.sum(A.data**2)) if issparse(A) else np.linalg.norm(A, 'fro')\n",
        "\n",
        "    def reset(self):\n",
        "        # Warm-start with power method\n",
        "        self.state = power_method(self.A)\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        action = np.array(action)\n",
        "        action /= np.linalg.norm(action) + 1e-8\n",
        "        self.state = action\n",
        "        # Compute residual norm\n",
        "        if issparse(self.A):\n",
        "            residual = self.A.dot(action) - self.target_eigenvalue * action\n",
        "        else:\n",
        "            residual = self.A @ action - self.target_eigenvalue * action\n",
        "        residual_norm = np.linalg.norm(residual)\n",
        "        # Logarithmic scaling of residual norm\n",
        "        residual_reward = -np.log1p(residual_norm / (self.A_norm + 1e-8))\n",
        "        # Compute Rayleigh quotient deviation\n",
        "        rayleigh = (action @ (self.A.dot(action) if issparse(self.A) else self.A @ action)) / (np.dot(action, action) + 1e-8)\n",
        "        rayleigh_deviation = np.abs(rayleigh - self.target_eigenvalue) / (np.abs(self.target_eigenvalue) + 1e-8)\n",
        "        # Combined reward with increased Rayleigh weight\n",
        "        reward = residual_reward - 0.5 * rayleigh_deviation\n",
        "        done = False\n",
        "        return self.state, reward, done, {}\n",
        "\n",
        "# Function to compute cosine distance\n",
        "def cosine_distance(v1, v2):\n",
        "    v1 = v1 / (np.linalg.norm(v1) + 1e-8)\n",
        "    v2 = v2 / (np.linalg.norm(v2) + 1e-8)\n",
        "    cos_sim = np.abs(np.dot(v1, v2))\n",
        "    cos_sim = min(cos_sim, 1.0)  # Handle numerical errors\n",
        "    return np.arccos(cos_sim) / np.pi  # Normalized to [0, 1]\n",
        "\n",
        "# Function to find dominant eigenvalue and compute eigenvector using RL\n",
        "def compute_dominant_eigenvector(A, timesteps=200000, eval_steps=1000):\n",
        "    # Ensure matrix is symmetric\n",
        "    if issparse(A):\n",
        "        A = (A + A.T) / 2\n",
        "    else:\n",
        "        A = (A + A.T) / 2\n",
        "\n",
        "    # Compute dominant eigenvalue and eigenvector using scipy\n",
        "    eigvals, eigvecs = eigsh(A, k=1, which='LA') if issparse(A) else np.linalg.eigh(A)\n",
        "    dominant_eigenvalue = eigvals[-1] if not issparse(A) else eigvals[0]\n",
        "    true_eigenvector = eigvecs[:, -1] if not issparse(A) else eigvecs[:, 0]\n",
        "    print(\"Dominant eigenvalue (scipy):\", dominant_eigenvalue)\n",
        "\n",
        "    # Initialize environment and SAC model\n",
        "    env = EigenvectorEnv(A, dominant_eigenvalue)\n",
        "    policy_kwargs = dict(net_arch=[512, 256, 128])\n",
        "    model = SAC(\n",
        "        'MlpPolicy',\n",
        "        env,\n",
        "        verbose=1,\n",
        "        learning_rate=0.0001,\n",
        "        buffer_size=1000000,\n",
        "        ent_coef='auto',\n",
        "        policy_kwargs=policy_kwargs,\n",
        "        device='cpu'  # Avoid GPU issues with MLP policy\n",
        "    )\n",
        "    model.learn(total_timesteps=timesteps)\n",
        "\n",
        "    # Evaluate to find best eigenvector\n",
        "    obs = env.reset()\n",
        "    best_reward = -np.inf\n",
        "    best_vec = None\n",
        "\n",
        "    for _ in range(eval_steps):\n",
        "        action, _ = model.predict(obs, deterministic=True)  # Use deterministic policy for evaluation\n",
        "        obs, reward, _, _ = env.step(action)\n",
        "        if reward > best_reward:\n",
        "            best_reward = reward\n",
        "            best_vec = obs\n",
        "\n",
        "    print(\"Approximated eigenvector (RL):\", best_vec)\n",
        "    # Compute residual norm for verification\n",
        "    residual_norm = np.linalg.norm(A @ best_vec - dominant_eigenvalue * best_vec) if not issparse(A) else np.linalg.norm(A.dot(best_vec) - dominant_eigenvalue * best_vec)\n",
        "    print(\"Residual norm ||Ax - Î»x||:\", residual_norm)\n",
        "    # Compute cosine distance for accuracy\n",
        "    cos_dist = cosine_distance(best_vec, true_eigenvector)\n",
        "    print(\"Cosine distance to true eigenvector:\", cos_dist)\n",
        "\n",
        "    return dominant_eigenvalue, best_vec, cos_dist\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFqq3-yXTubg"
      },
      "source": [
        "# Test on Large sparse matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flVouBl1OBmu",
        "outputId": "7cd3d883-5c37-492b-d015-3a2ca7bed8f1"
      },
      "outputs": [],
      "source": [
        "# Test with large sparse symmetric matrix\n",
        "from scipy.sparse import random as sparse_random\n",
        "np.random.seed(42)\n",
        "size = 1000\n",
        "A_sparse = sparse_random(size, size, density=0.01, format='csr')\n",
        "print(\"\\nTesting with sparse matrix:\")\n",
        "eigenvalue, eigenvector, cos_dist_sparse = compute_dominant_eigenvector(A_sparse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_e2H9UtP7Ts"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGDOb3lhTos6"
      },
      "source": [
        "# Test on dense matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MS1URBAJN_32"
      },
      "outputs": [],
      "source": [
        "# Test with dense symmetric matrix\n",
        "np.random.seed(42)\n",
        "size = 5\n",
        "A_dense = np.random.randn(size, size)\n",
        "A_dense = (A_dense + A_dense.T) / 2\n",
        "print(\"\\nTesting with dense matrix:\")\n",
        "eigenvalue, eigenvector, cos_dist_dense = compute_dominant_eigenvector(A_dense)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QGDOb3lhTos6"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
